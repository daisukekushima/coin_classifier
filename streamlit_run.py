import av
import cv2
import numpy as np
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import time
import os
from datetime import datetime
from pathlib import Path

from app import CoinRecognizer

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒ­ã‚°è¨­å®š
ROOT_DIR = Path(__file__).parent
DATA_YAML_PATH = ROOT_DIR / "datasets" / "data.yaml"
PROJECT_BASE = ROOT_DIR / "finetuning_result"
MODEL_PATH = PROJECT_BASE /"yolo11n"/"best.pt"
recognizer = CoinRecognizer(model_path=str(MODEL_PATH))

LOG_DIR = ROOT_DIR / "classifier_result"
LOG_DIR.mkdir(parents=True, exist_ok=True)
# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
st.session_state.setdefault("recognized", False)
st.session_state.setdefault("amount", None)
st.session_state.setdefault("result_img", None)
st.session_state.setdefault("raw_img", None)
st.session_state.setdefault("annotations", None)
st.session_state.setdefault("stream_started", False)  # ã‚¹ãƒˆãƒªãƒ¼ãƒ èµ·å‹•ã®åˆæœŸåŒ–ãƒ•ãƒ©ã‚°

# å‹•ç”»å‡¦ç†ã‚¯ãƒ©ã‚¹
class VideoProcessor(VideoTransformerBase):
    def __init__(self):
        self.last_time = 0
        self.interval = 1.0
        self.result_img = None
        self.recognized = False
        self.amount = None
        self.raw_img = None
        self.annotations = []

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24")
        now = cv2.getTickCount() / cv2.getTickFrequency()
        output_img = img

        # èªè­˜æ¸ˆã¿ãªã‚‰çµæœç”»åƒã‚’å¸¸ã«è¿”ã™ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ã—ã¦ï¼‰
        if self.recognized and self.result_img is not None:
            return av.VideoFrame.from_ndarray(self.result_img, format="bgr24")

        if now - self.last_time >= self.interval:
            self.last_time = now
            detected_img, total_amount, annotations, raw_img = recognizer.recognize(img)
            print(f"[recv] detected_img shape={detected_img.shape}, total_amount={total_amount}")

            # èªè­˜æˆåŠŸæ™‚
            if total_amount and total_amount > 0:
                self.result_img = detected_img
                self.amount = total_amount
                self.recognized = True
                self.raw_img = raw_img
                self.annotations = annotations
                output_img = detected_img
            else:
                output_img = detected_img

        return av.VideoFrame.from_ndarray(output_img, format="bgr24")


# --- ã‚¿ã‚¤ãƒˆãƒ« --- 
st.title("ğŸ’° ç¡¬è²¨è­˜åˆ¥ãƒ„ãƒ¼ãƒ«")

# --- å·¦å³ã‚«ãƒ©ãƒ é…ç½® --- 
col1, col2 = st.columns([2, 1])

with col1:
    # WebRTC ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
    ctx = webrtc_streamer(
        key="example",
        video_processor_factory=VideoProcessor,
        media_stream_constraints={
            "video": {"width": {"ideal": 1920}, "height": {"ideal": 1080}},
            "audio": False
        }
    )

with col2:
    st.subheader("ğŸ”èªè­˜çµæœ")

    # video_processor ãŒå­˜åœ¨ã—ãŸã‚‰å‚ç…§
    processor = None
    if ctx.video_processor:
        processor = ctx.video_processor
        # æ–°ã—ã„ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹æ™‚ã« processor ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦ãŠã
        if not st.session_state["stream_started"]:
            try:
                processor.amount = None
                processor.result_img = None
                processor.recognized = False
                st.session_state["stream_started"] = True
            except Exception:
                # å®‰å…¨ã«ç„¡è¦–ï¼ˆãŸã¾ã« race ãŒèµ·ãã‚‹ï¼‰
                pass

    # --- è‡ªå‹•å†æç”»ï¼ˆãƒãƒ¼ãƒªãƒ³ã‚°ï¼‰ ---
    # streamlit-autorefresh ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ã£ã¦éãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã«å†å®Ÿè¡Œ
    try:
        from streamlit_autorefresh import st_autorefresh
        # 500ms ã”ã¨ã«è‡ªå‹•ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ï¼ˆèª¿æ•´å¯ï¼‰
        st_autorefresh(interval=500, key="autorefresh")
    except Exception:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ‰‹å‹•æ›´æ–°ãƒœã‚¿ãƒ³ï¼ˆè‡ªå‹•æ›´æ–°ãŒç„¡ã‘ã‚Œã°ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ›´æ–°ã™ã‚‹ï¼‰
        st.write("è‡ªå‹•æ›´æ–°ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚`pip install streamlit-autorefresh` ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
        if st.button("æ›´æ–°"):
            st.experimental_rerun()

    # --- èªè­˜ãƒ•ãƒ©ã‚°ãŒç«‹ã£ã¦ã„ãŸã‚‰ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢ã—ã¦çµæœè¡¨ç¤ºã¸ ---
    if processor is not None and getattr(processor, "recognized", False):
        # WebRTC ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢ï¼ˆå®‰å…¨ã«ä½•åº¦å‘¼ã‚“ã§ã‚‚ã‚ˆã„ï¼‰
        try:
            ctx.stop()
        except Exception:
            # ctx.stop() ãŒä¾‹å¤–ã‚’å‡ºã™ã“ã¨ã¯ç¨€ãªã®ã§ç„¡è¦–ã—ã¦å…ˆã¸é€²ã‚€
            pass

        # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ç§»ã™
        st.session_state["recognized"] = True
        st.session_state["amount"] = getattr(processor, "amount", None)
        st.session_state["result_img"] = getattr(processor, "result_img", None)
        st.session_state["raw_img"] = getattr(processor, "raw_img", None)
        st.session_state["annotations"] = getattr(processor, "annotations", [])

    # --- å³å´ã® UI è¡¨ç¤º ---
    if st.session_state["recognized"]:
        st.metric("ğŸ’µ åˆè¨ˆé‡‘é¡", f"{st.session_state['amount']} å††")

        with st.expander("ğŸ“Œ ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º"):
            if st.session_state["annotations"]:
                # è¡Œç•ªå·ã‚’ä»˜ã‘ã‚‹
                annotated_lines = [
                    f"{i+1:>2}: {line}"  # å³æƒãˆã§3æ¡ã®è¡Œç•ªå·ã‚’ä»˜ã‘ã‚‹
                    for i, line in enumerate(st.session_state["annotations"])
                ]
                st.code("\n".join(annotated_lines), language="")
            else:
                st.write("ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

        # --- ä¿å­˜ãƒœã‚¿ãƒ³ --- 
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        if st.button("ğŸ”½ ãƒ‡ãƒ¼ã‚¿ä¿å­˜"):
            save_path = os.path.join(LOG_DIR, f"recognized_coin_{timestamp}.png")
            save_path_raw = os.path.join(LOG_DIR, f"raw_img_{timestamp}.png")
            save_path_txt = Path(LOG_DIR) / f"raw_img_{timestamp}.txt"
            if st.session_state["result_img"] is not None:
                cv2.imwrite(save_path, st.session_state["result_img"])
            if st.session_state["raw_img"] is not None:
                cv2.imwrite(save_path_raw, st.session_state["raw_img"])
            with open(save_path_txt, "w", encoding="utf-8") as f:
                if st.session_state["annotations"]:
                    f.write("\n".join(st.session_state["annotations"]))
            st.info(f"ç”»åƒã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")

        # --- å†èªè­˜ãƒœã‚¿ãƒ³ ---
        if st.button("ğŸ”„ å†èªè­˜"):
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµæœã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦æ–°ã—ã„ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä½œã‚‹
            st.session_state["recognized"] = False
            st.session_state["amount"] = None
            st.session_state["result_img"] = None
            st.session_state["raw_img"] = None
            st.session_state["annotations"] = None
            st.session_state["stream_started"] = False
            # æ–°ã—ã„ã‚­ãƒ¼ã§ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å†ç”Ÿæˆï¼ˆãƒšãƒ¼ã‚¸å†å®Ÿè¡Œæ™‚ã« col1 å´ã® webrtc_streamer ãŒæ–°ã—ã„ã‚­ãƒ¼ã‚’ä½¿ã£ã¦èµ·å‹•ã™ã‚‹ï¼‰
