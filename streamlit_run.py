import av
import cv2
import numpy as np
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import time
import os
from datetime import datetime
from pathlib import Path

from app import CoinRecognizer

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒ­ã‚°è¨­å®š
model_path = r"finetuning_result/train/weights/best.pt"
recognizer = CoinRecognizer(model_path=model_path)
log_dir = "classifier_result"
os.makedirs(log_dir, exist_ok=True) 

# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
st.session_state.setdefault("recognized", False)
st.session_state.setdefault("amount", None)
st.session_state.setdefault("result_img", None)

# å‹•ç”»å‡¦ç†ã‚¯ãƒ©ã‚¹
class VideoProcessor(VideoTransformerBase):
    def __init__(self):
        self.last_time = 0
        self.interval = 1.0
        self.result_img = None
        self.recognized = False
        self.amount = None

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24")
        now = cv2.getTickCount() / cv2.getTickFrequency()
        output_img = img

        if self.recognized and self.result_img is not None:
            return av.VideoFrame.from_ndarray(self.result_img, format="bgr24")

        if now - self.last_time >= self.interval:
            self.last_time = now
            detected_img, total_amount, annotations, raw_img = recognizer.recognize(img)
            print(f"[recv] detected_img shape={detected_img.shape}, total_amount={total_amount}")

            if total_amount and total_amount > 0:
                self.result_img = detected_img
                self.amount = total_amount
                self.recognized = True
                self.raw_img = raw_img
                self.annotations = annotations
                output_img = detected_img
            else:
                output_img = detected_img

        return av.VideoFrame.from_ndarray(output_img, format="bgr24")


# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ’° ç¡¬è²¨è­˜åˆ¥ãƒ„ãƒ¼ãƒ«")

# å·¦å³ã‚«ãƒ©ãƒ é…ç½®
col1, col2 = st.columns([2, 1])

with col1:
    ctx = webrtc_streamer(
        key="example",
        video_processor_factory=VideoProcessor,
        media_stream_constraints={
            "video": {"width": {"ideal": 1920}, "height": {"ideal": 1080}},
            "audio": False
        }
    )

with col2:
    st.subheader("èªè­˜çµæœ")

    if ctx.video_processor:
        processor = ctx.video_processor
        processor.amount = None
        processor.result_img = None
        processor.recognized = False

        # èªè­˜ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
        while not processor.recognized:
            time.sleep(0.5)

        if processor.recognized:
            st.session_state["recognized"] = True
            st.session_state["amount"] = processor.amount
            st.session_state["result_img"] = processor.result_img
            st.session_state["raw_img"] = processor.raw_img
            st.session_state["annotations"] = processor.annotations

    if st.session_state["recognized"]:
        st.metric("ğŸ’µ åˆè¨ˆé‡‘é¡", f"{st.session_state['amount']} å††")

        with st.expander("ğŸ“Œ ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º"):
            st.code("\n".join(st.session_state["annotations"]), language="")

        # ä¿å­˜ãƒœã‚¿ãƒ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        if st.button("ğŸ”½ ç”»åƒã‚’ä¿å­˜"):
            save_path = os.path.join(log_dir, f"recognized_coin_{timestamp}.png")
            save_path_raw = os.path.join(log_dir, f"raw_img_{timestamp}.png")
            save_path_txt = Path(log_dir) / f"raw_img_{timestamp}.txt"
            cv2.imwrite(save_path, st.session_state["result_img"])
            cv2.imwrite(save_path_raw, st.session_state["raw_img"])
            with open(save_path_txt, "w", encoding="utf-8") as f:
                f.write("\n".join(st.session_state["annotations"]))
            st.info(f"ç”»åƒã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")

        # å†èªè­˜ãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ å†èªè­˜"):
            st.session_state["recognized"] = False
            st.session_state["amount"] = None
            st.session_state["result_img"] = None
            new_key = f"example_{int(time.time())}"
            ctx = webrtc_streamer(
                key=new_key,
                video_processor_factory=VideoProcessor,
                media_stream_constraints={"video": True, "audio": False}
            )
            st.stop()
